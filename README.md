# Building Perceptron

> "The perceptron is capable of generalization and abstraction; it may recognize similarities between patterns which are not identical." - Frank Rosenblatt

# üìñ Contexte du Projet
Ce projet s'inscrit dans le cadre d'une initiation au Deep Learning √† La Plateforme_. Il vise √† comprendre et impl√©menter le Perceptron, le premier neurone artificiel invent√© par Frank Rosenblatt, consid√©r√© comme la pierre angulaire de l'apprentissage automatique moderne.

L'objectif principal est de d√©velopper une compr√©hension approfondie des concepts fondamentaux du Machine Learning √† travers l'impl√©mentation d'un Perceptron en Python, puis de tester ce mod√®le sur un cas d'usage r√©el avec le dataset Breast Cancer Wisconsin.

# üéØ Objectifs du Projet

## Phase 1 : Fondements Th√©oriques

### Machine Learning vs. Deep Learning : d√©finitions et comparaison

#### Machine Learning (Apprentissage Automatique)

Le Machine Learning regroupe des m√©thodes permettant √† une machine d‚Äôapprendre √† partir de donn√©es sans √™tre explicitement programm√©e pour chaque t√¢che. Les algorithmes classiques incluent :

- R√©gressions lin√©aires et logistiques
- Arbres de d√©cision et for√™ts al√©atoires
- SVM (Support Vector Machines)
- k-nearest neighbors

Ils reposent souvent sur des caract√©ristiques (features) ing√©nieusement extraites et n√©cessitent un pr√©traitement humain des donn√©es (s√©lection, transformation, normalisation).

#### Deep Learning (Apprentissage Profond)

Le Deep Learning est un sous-ensemble du Machine Learning qui utilise des r√©seaux de neurones profonds (plusieurs couches de neurones artificiels) capables d‚Äôapprendre automatiquement les repr√©sentations des donn√©es √† diff√©rents niveaux d‚Äôabstraction (features hi√©rarchiques).

Aspect                            | Machine              | Learning Deep Learning              |
----------------------------------|----------------------|-------------------------------------|
Caract√©ristiques                  | Conception manuelle  | Apprentissage automatique           |
Complexit√© des donn√©es            | Mod√©r√©e              | Tr√®s √©lev√©e (images, sons, textes‚Ä¶) |
Quantit√© de donn√©es               | Moyenne              | Grandes quantit√©s requises          |
Puissance de calcul               | Ordinateur classique | GPU/TPU souvent n√©cessaires         |
Performances sur t√¢ches complexes | Limit√©es             | Excellentes                         |

### Quand utiliser l‚Äôun plut√¥t que l‚Äôautre ?

#### Machine Learning

- Jeux de donn√©es petits √† moyens
- Probl√®mes bien compris o√π les features manuelles sont efficaces
- Contraintes de puissance de calcul

#### Deep Learning

- Donn√©es volumineuses et non structur√©es (images, audio, texte)
- Besoin d‚Äôextraire des repr√©sentations complexes sans expertise m√©tier pouss√©e
- Disponibilit√© de ressources GPU et tol√©rance √† des temps d‚Äôentra√Ænement plus longs

### Applications du Deep Learning

Voici trois exemples embl√©matiques, inspir√©s d‚ÄôAI Experiments et d‚ÄôOpenAI :

#### 1. Diagnostic m√©dical assist√© par imagerie

Des r√©seaux de neurones convolutionnels (CNN) analysent des radiographies ou IRM pour d√©tecter automatiquement des tumeurs ou anomalies. Cette approche acc√©l√®re le diagnostic du cancer et am√©liore la pr√©cision des d√©pistages.

#### 2. V√©hicules autonomes

Les syst√®mes embarqu√©s s‚Äôappuient sur des CNN et des vision transformers pour reconna√Ætre en temps r√©el les pi√©tons, panneaux de signalisation et autres v√©hicules, permettant √† la voiture de naviguer en toute s√©curit√© sans intervention humaine.

#### 3. Traitement automatique du langage naturel (NLP)

Les mod√®les de type Transformers (GPT, BERT) g√®rent la traduction, la g√©n√©ration de texte et les chatbots. Par exemple, ChatGPT comprend et produit un langage proche du dialogue humain pour l‚Äôassistance en ligne ou la cr√©ation de contenu.

### Le Perceptron

##### Introduction

Le Perceptron est le premier mod√®le de neurone artificiel, mis au point par Frank Rosenblatt en 1957. Il sert de brique de base √† l‚Äôapprentissage profond. Ce dossier explique pas √† pas le fonctionnement du perceptron, ses limites, puis montre comment l‚Äô√©tendre et l‚Äôutiliser dans des contextes plus complexes.

#### 1. **Qu‚Äôest-ce qu‚Äôun Perceptron ?**

Un perceptron est un programme informatique qui imite grossi√®rement le comportement d‚Äôun neurone du cerveau :

- **Neurone biologique** : capte des signaux via des extensions appel√©es dendrites, les additionne dans le corps cellulaire, et, si le total d√©passe un seuil, g√©n√®re un signal √©lectrique (potentiel d‚Äôaction) transmis √† d‚Äôautres neurones.

- **Perceptron** : re√ßoit des entr√©es num√©riques x1,x2,‚Ä¶,xn, multiplie chacune par un poids w1,w2,‚Ä¶,wn, ajoute un biais b, puis d√©cide d‚Äôenvoyer un ‚Äúoui‚Äù (1) ou un ‚Äúnon‚Äù (0) selon le r√©sultat.

Cette structure lui permet de distinguer deux cat√©gories d‚Äôobjets ou de donn√©es quand elles sont s√©parables par une ligne droite (en deux dimensions) ou un plan (en plusieurs dimensions).

#### 2. **Formule math√©matique et signification des termes**

La d√©cision du perceptron se calcule ainsi :

<div align="center">
   <img src="images/formule_perceptron.png" alt="y_hat = activation(w1 * x1 + w2 * x2 + ... + wn * xn + b)" style="width: 40%; max-width: 900px;">
</div>

- ≈∑  : pr√©diction du perceptron
- z : somme pond√©r√©e des entr√©es plus le biais (√©quivalent du potentiel d‚Äôaction).
- f : fonction d‚Äôactivation qui convertit z en 0 ou 1.
- wi : poids attribu√© √† cette entr√©e (force du lien synaptique).
- xi : valeur de la i-√®me entr√©e (ex. intensit√© d‚Äôun pixel).
- b : biais, permet de d√©caler la fronti√®re de d√©cision.

La fonction d‚Äôactivation la plus simple est le seuil de Heaviside :

<div align="center">
   <img src="images/regle_activation.png" alt="Fonction d'activation" style="width: 30%; max-width: 900px;">
</div>

#### 3. Comment apprend-on ?

L‚Äôapprentissage consiste √† ajuster les poids wi et le biais b pour que le perceptron donne la bonne r√©ponse sur des exemples connus. on utlise la r√®gle d'apprentissage du perceptron (mise √† jour des poids) :

<div align="center">
   <img src="images/regle_apprentissage.png" alt="Fonction d'apprentissage" style="width: 30%; max-width: 900px;">
</div>

- Œ∑ : taux d'apprentissage
- y : label attendu

Ce formalisme est la base du perceptron simple, utilis√© pour la classification binaire lin√©aire.

1. Calculer la sortie : ≈∑ = f(‚àëwi √ó xi + b)
2. Mesurer l'erreur : Œ¥ = y - ≈∑  
3. Mettre √† jour les poids : wi = wi + Œ∑ √ó Œ¥ √ó xi
4. Mettre √† jour le biais : b = b + Œ∑ √ó Œ¥
    o√π Œ∑ est le taux d‚Äôapprentissage, un petit nombre (ex. 0,01) qui d√©termine la vitesse d‚Äôajustement.

On r√©p√®te ces √©tapes sur tous les exemples, plusieurs fois (plusieurs √©poques), jusqu‚Äô√† obtenir un taux de bonnes r√©ponses satisfaisant.

#### 4. Processus d‚Äôentra√Ænement complet

1. Initialisation al√©atoire : attribuer de petits poids et biais proches de z√©ro.
2. Boucle d‚Äô√©poques :
      - Pour chaque exemple :
            - Pr√©dire y^
            - Calculer l‚Äôerreur Œ¥
            - Ajuster wi et b

3. V√©rification : arr√™ter si l‚Äôerreur moyenne tombe en-dessous d‚Äôun seuil ou apr√®s un nombre fixe d‚Äô√©poques.

#### 5. Limites du Perceptron

- Donn√©es lin√©airement s√©parables : il ne r√©sout que les probl√®mes o√π une ligne ou un plan peut s√©parer les deux classes (ex. XOR n‚Äôest pas s√©parable).
- Convergence non garantie si les donn√©es ne satisfont pas cette condition.
- Fronti√®re plane : incapable de mod√©liser des formes de s√©paration complexes.
- Sensibilit√© aux choix du taux d‚Äôapprentissage et √† l‚Äôinitialisation des poids.

#### 6. Aller plus loin : perceptrons multicouches et backpropagation

Pour traiter des donn√©es non lin√©aires, on assemble plusieurs perceptrons en couches :
- Chaque couche applique la m√™me op√©ration (somme pond√©r√©e + fonction d‚Äôactivation) sur la sortie de la couche pr√©c√©dente.
- On appelle cela un r√©seau de neurones multicouches (MLP).
- L‚Äôalgorithme de r√©tropropagation (backpropagation) calcule les d√©riv√©es de l‚Äôerreur par rapport √† chaque poids en propageant l‚Äôerreur √† rebours, puis ajuste tous les poids simultan√©ment.

#### 7. Versions am√©lior√©es et bonnes pratiques

- Fonctions d‚Äôactivation modernes : ReLU, tanh, sigmo√Øde, qui g√®rent mieux le ph√©nom√®ne de gradient.
- Optimiseurs avanc√©s : Adam, RMSProp, qui adaptent automatiquement le taux d‚Äôapprentissage.
- R√©gularisation : Dropout, weight decay, pour √©viter le surapprentissage.
- Normalisation : Batch Normalization, pour stabiliser et acc√©l√©rer l‚Äôentra√Ænement.

#### 8. Exemples de code Python (orient√© objet)

*python*

```
import numpy as np

class Perceptron:
    def __init__(self, n_inputs, lr=0.01):
        self.w = np.random.randn(n_inputs) * 0.01
        self.b = 0.0
        self.lr = lr

    def activation(self, z):
        return 1 if z >= 0 else 0

    def predict(self, X):
        z = np.dot(X, self.w) + self.b
        return self.activation(z)

    def train(self, X_train, y_train, epochs=100):
        for _ in range(epochs):
            for x, y in zip(X_train, y_train):
                y_pred = self.predict(x)
                delta = y - y_pred
                self.w += self.lr * delta * x
                self.b += self.lr * delta
```

#### Test rapide :

**Donn√©es factices**

*python*

```
X = np.random.randn(200, 2)
y = np.where(X[:,0] + X[:,1] > 0, 1, 0)

model = Perceptron(n_inputs=2, lr=0.01)
model.train(X, y, epochs=50)

preds = np.array([model.predict(x) for x in X])
print("Pr√©cision :", np.mean(preds == y))

<div style="page-break-after: always;"></div>
```

## Phase 2 : Compr√©hension et Analyse des Donn√©es

Statistiques descriptives, visualisations, corr√©lations

D√©tection des outliers et valeurs manquantes

### üìä Donn√©es Utilis√©es

**Dataset** : Breast Cancer Wisconsin
**Source** : UCI Machine Learning Repository (https://archive.ics.uci.edu/datasets)

- Probl√©matique : Classification binaire pour le diagnostic du cancer du sein

- Caract√©ristiques : 30 features num√©riques d√©crivant les caract√©ristiques des noyaux cellulaires

Structure du Dataset Breast Cancer Wisconsin

### üîç Vue d'ensemble

- 569 √©chantillons (212 malins (37%), 357 b√©nins(63%))
- 32 colonnes : 1 ID + 1 diagnostic + 30 caract√©ristiques num√©riques

Source : Images FNA (biopsie √† l'aiguille fine) de masses mammaires

Les caract√©ristiques sont calcul√©es √† partir d'une image num√©ris√©e d'une ponction √† l'aiguille fine (PAF) d'une masse mammaire. Elles d√©crivent les caract√©ristiques des noyaux cellulaires pr√©sents sur l'image.

Objectif : Classification binaire pour diagnostic du cancer du sein

### üìä Variables du dataset

Variable  |	Description                        | Utilit√©        |
----------|------------------------------------|----------------|
id	      |Identifiant unique de l'√©chantillon | Identification |
diagnosis |	Diagnostic (M = malin, B = b√©nin)  | Variable cible |

### üß¨ Les 30 caract√©ristiques (features)

Chaque caract√©ristique de base est calcul√©e sous 3 formes diff√©rentes :

Suffixes des colonnes :
- _mean (colonnes 3-12) : Valeurs moyennes
- _se (colonnes 13-22) : Erreurs standard (variabilit√©)
- _worst (colonnes 23-32) : Pires valeurs (moyenne des 3 plus extr√™mes)

10 caract√©ristiques de base mesur√©es sur le noyau cellulaire :

*radius : Distance moyenne centre-p√©rim√®tre (taille)*
D√©finition : Distance moyenne entre le centre du noyau cellulaire et tous les points de son p√©rim√®tre.
- Calcul concret : On identifie le centre g√©om√©trique du noyau, puis on mesure la distance √† chaque point du contour et on fait la moyenne.
- Valeurs typiques : 6-28 unit√©s (pixels)
- Signification clinique : Un rayon √©lev√© indique des cellules plus grosses, souvent associ√©es √† la malignit√©.
- Pourquoi c'est important : Les cellules canc√©reuses ont tendance √† √™tre plus volumineuses que les cellules normales.

*texture : √âcart-type des niveaux de gris (rugosit√©)*
D√©finition : √âcart-type des intensit√©s de niveaux de gris dans une r√©gion du noyau.
- Calcul concret : On analyse la variation de luminosit√© pixel par pixel dans le noyau (homog√®ne vs h√©t√©rog√®ne).
- Valeurs typiques : 9-40 unit√©s
- Signification clinique : Texture √©lev√©e = noyau "granuleux" ou irr√©gulier, caract√©ristique des cellules malignes.
- Analogie : Comme la diff√©rence entre une surface lisse (faible texture) et rugueuse (forte texture).

*perimeter : Longueur du contour (circonf√©rence)*
D√©finition : Longueur totale du contour du noyau cellulaire.
- Calcul concret : Somme des distances entre tous les pixels adjacents formant le contour.
- Valeurs typiques : 40-190 unit√©s
- Signification clinique : P√©rim√®tre √©lev√© peut indiquer une forme irr√©guli√®re ou une taille importante.
- Relation : Fortement corr√©l√© au rayon et √† l'aire.

*area : Surface du noyau (taille 2D)*
D√©finition : Surface totale occup√©e par le noyau cellulaire.
- Calcul concret : Nombre de pixels √† l'int√©rieur du contour du noyau.
- Valeurs typiques : 140-2500 unit√©s¬≤
- Signification clinique : Aire importante = cellule volumineuse, souvent maligne.
- Note : Aire = œÄ √ó rayon¬≤, d'o√π la forte corr√©lation entre ces variables.

*smoothness : Variation locale du rayon (r√©gularit√©)*
D√©finition : Variation locale des longueurs de rayon (√©cart-type des rayons).
- Calcul concret : On mesure plusieurs rayons depuis le centre et on calcule leur variabilit√©.
- Valeurs typiques : 0.05-0.16 unit√©s
- Signification clinique : Faible lissage = contour irr√©gulier, "bossel√©", typique des cellules malignes.
- Interpr√©tation : 0 = cercle parfait, valeurs √©lev√©es = forme tr√®s irr√©guli√®re.

*compactness : P√©rim√®tre¬≤/aire - 1.0 (forme)*
D√©finition : Formule (p√©rim√®tre¬≤ / aire) - 1.0
- Calcul concret : Mesure de l'efficacit√© g√©om√©trique de la forme.
- Valeurs typiques : 0.02-0.35 unit√©s
- Signification clinique : Compacit√© √©lev√©e = forme √©tal√©e ou irr√©guli√®re.
- R√©f√©rence : Un cercle parfait a une compacit√© de 0, les formes irr√©guli√®res ont des valeurs plus √©lev√©es.

*concavity : S√©v√©rit√© des portions concaves (creux)*
D√©finition : S√©v√©rit√© des portions concaves du contour (zones qui "rentrent vers l'int√©rieur").
- Calcul concret : Somme des profondeurs des indentations divis√©e par la surface.
- Valeurs typiques : 0-0.43 unit√©s
- Signification clinique : Concavit√© √©lev√©e = nombreux "creux" dans le contour, signe de malignit√©.
- Visualisation : Comme mesurer la profondeur des "entailles" dans le contour.

*concave_points : Nombre de portions concaves (irr√©gularit√©)*
D√©finition : Nombre de portions concaves sur le contour du noyau.
- Calcul concret : Comptage des zones o√π le contour "rentre vers l'int√©rieur".
- Valeurs typiques : 0-0.2 unit√©s (normalis√© par la taille)
- Signification clinique : Plus il y a de points concaves, plus la forme est irr√©guli√®re et potentiellement maligne.
- Diff√©rence avec concavity : Ici on compte, l√†-bas on mesure la profondeur.

*symmetry : Mesure de sym√©trie du noyau*
D√©finition : Mesure de la sym√©trie du noyau par rapport √† son centre.
- Calcul concret : Comparaison entre les moiti√©s droite/gauche et haut/bas du noyau.
- Valeurs typiques : 0.1-0.3 unit√©s
- Signification clinique : Asym√©trie √©lev√©e = forme d√©s√©quilibr√©e, souvent associ√©e √† la malignit√©.
- Interpr√©tation : 0 = parfaitement sym√©trique, valeurs √©lev√©es = tr√®s asym√©trique.

*fractal_dimension : Complexit√© du contour (dimension fractale)*
D√©finition : Mesure math√©matique de la complexit√© du contour ("approximation de ligne de c√¥te" - 1).
- Calcul concret : Utilise l'algorithme de "coastline approximation" pour mesurer la rugosit√© du contour.
- Valeurs typiques : 1.0-2.1 unit√©s
- Signification clinique : Dimension fractale √©lev√©e = contour tr√®s complexe et irr√©gulier, caract√©ristique des cellules malignes.
- Analogie : Comme mesurer la complexit√© d'une c√¥te : plus elle est d√©coup√©e, plus sa dimension fractale est √©lev√©e.

### üéØ Variables les plus discriminantes

- *Taille* : radius_mean, area_mean, perimeter_mean
- *Forme* : concavity_mean, concave_points_mean, compactness_mean
- Variables *_worst* : souvent tr√®s informatives pour d√©tecter les cas extr√™mes

Cette structure permet d'analyser finement les caract√©ristiques morphologiques des cellules pour distinguer les tumeurs b√©nignes des malignes.



## Phase 3 : Pr√©paration des Donn√©es

Nettoyage des donn√©es

Normalisation/standardisation

R√©duction de dimensionnalit√© (PCA)

Division train/test

## Phase 4 : Impl√©mentation du Mod√®le

D√©velopper la classe Perceptron

Tests sur donn√©es factices pour validation

## Phase 5 : Application et √âvaluation

Entra√Ænement sur les vraies donn√©es pr√©par√©es

√âvaluation des performances

Analyse des r√©sultats et am√©liorations



# üõ†Ô∏è Outils et Technologies

## Langages et Frameworks

- Python : Langage principal du projet

- NumPy : Calculs num√©riques et alg√®bre lin√©aire

- Pandas : Manipulation et analyse de donn√©es

- Matplotlib/Seaborn : Visualisation de donn√©es

- Scikit-learn : Preprocessing et m√©triques d'√©valuation

# Techniques Appliqu√©es

## Programmation Orient√©e Objet : Architecture modulaire du Perceptron

- Analyse Exploratoire : Compr√©hension approfondie des donn√©es

- R√©duction de Dimensionnalit√© : Optimisation des features

- Validation Crois√©e : √âvaluation robuste du mod√®le

# üìÅ Structure du Repository

```
text
building-perceptron/
‚îú‚îÄ‚îÄ .env                    # environnement python
‚îú‚îÄ‚îÄ script.py                 # Classe Perceptron impl√©ment√©e
‚îú‚îÄ‚îÄ notebook.ipynb           # Analyse compl√®te et mod√©lisation
‚îú‚îÄ‚îÄ README.md               # Documentation du projet
‚îú‚îÄ‚îÄ Data/                   # Donn√©es du projet
‚îú‚îÄ‚îÄ visualizations/         # Graphiques et visualisations
‚îî‚îÄ‚îÄ requirements.txt        # D√©pendances Python
```

# üìà R√©sultats et Conclusions

## Performance du Perceptron

[Ins√©rer ici les m√©triques obtenues lors de l'√©valuation]

## Limites Identifi√©es

Le Perceptron pr√©sente certaines limitations inh√©rentes :

- Capacit√© limit√©e aux probl√®mes lin√©airement s√©parables

- Sensibilit√© √† l'initialisation des poids

- Convergence non garantie pour certains datasets

## Am√©liorations Propos√©es

- Impl√©mentation du Perceptron multi-couches

- Utilisation de fonctions d'activation non-lin√©aires

- Application de techniques de r√©gularisation

- Optimisation des hyperparam√®tres

# üìö Bibliographie
## Ressources Acad√©miques

- Rosenblatt, F. (1958). "The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain"

- Minsky, M., & Papert, S. (1969). "Perceptrons: An Introduction to Computational Geometry"

## Ressources Techniques

- Perceptron Algorithm with Code Example ML for beginners!

- Gradient Descent Simply Explained! ML for beginners with Code Example!

- Boruta-py Documentation

## Datasets
- Breast Cancer Wisconsin (Diagnostic) Dataset - UCI Machine Learning Repository

# üîÑ D√©veloppement et Maintenance

Ce projet a √©t√© d√©velopp√© dans le cadre de la formation en Intelligence Artificielle et Data Science √† La Plateforme. Il constitue une base solide pour l'apprentissage des concepts fondamentaux du Machine Learning et peut √™tre √©tendu avec des algorithmes plus complexes.